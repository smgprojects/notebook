---
layout: post
title: "clement2012"
date: 2016-03-21 22:03
tags: [soundbashing, visualization, music]
categories:
- Readings
...

* Table of Contents
{:toc}

<h4>{% reference clement2012distant %}</h4>

### Clement - "Distant Listening: On Data Visualisations and Noise in the Digital Humanities" ###

nb - I turned the html version of this paper into a pdf so I could read and annotate it in Skim, wherein I have a script to export all my annotations as the markdown you see below.

### Background: reading Steinian texts with music and with computers ###

'use musical composition and computational tools to help express something inherent to Stein’s texts that was otherwise obscured with more traditional readings' <-    
[Page 5](sk://clement2013distant#5)

'readers argue that setting a Steinian text to music is a welcome abstraction that brings the text to new heights of expression, while computing them seems to concretise their subtleties and diminish their expressive possibilities.'   
[Page 5](sk://clement2013distant#5)

'In each of these cases, music brings out latent meanings in an otherwise inexpressive or unreadable text.' <- the texts, as texts, are too dense, too troublesome; music makes the meaning   
[Page 6](sk://clement2013distant#6)

'This attempt to engage with the meaning of the text by setting it to music is similar to attempts to read Stein texts with computational analysis.'   
[Page 6](sk://clement2013distant#6)

'In either case, Bucknell and Goldsmith see musical and computational interventions as key to reading and understanding the texts’ ongoing processes of meaning-making.'   
[Page 6](sk://clement2013distant#6)

'Dusman’s narration of her entire process of setting Stein’s text to music is illuminating in terms of understanding how the process of musical annotation and computation share similar underlying methods for scaffolding (setting concrete and abstract textual elements to an external system) in order to express a reading of the text.'   
[Page 7](sk://clement2013distant#7)

'Systematically concretising the text was just one phase in the interpretive process: musical and computational transpositions create another level of abstraction with which the interpreter engages.' <- this process is really interesting, especially when we think of things that are already abstractions, eg, topic models, word vectors, frequencies?   
[Page 7](sk://clement2013distant#7)

### What computational and musical renditions tell us about the nature of representing literary texts ###

'Using digital and musical interventions to interpret texts means both concretising and abstracting as part of the interpretive experience.'   
[Page 8](sk://clement2013distant#8)

Yet, it is at the moment at which the text—whether it has been rendered in paragraphs on the typographical or manuscript page or in musical staffs or as data in bar graphs—is “played” that the reader or listener enters that space of interpretive activity. <- [how does the listener respond to my sonifications?](#todo:)   
[Page 8](sk://clement2013distant#8)

'A sense of “playing” a visualisation is important to note in the context of this discussion because, in the digital humanities, we still tend to “read” a visualisation on a computer screen, whether in tables, in heat maps, or in elaborate and networked spidery nodes.' < - so let's get beyond the screen essentialism   
[Page 8](sk://clement2013distant#8)

'One “reads” a visualisation, but to “play” the visualisation is to engage the spatialised interpretation of that visualisation as an embodied reader in a situated context within a specific hermeneutical framework.'   
[Page 9](sk://clement2013distant#9)

'First, in seeming contrast to the move from musical score to performance—from two-dimensional representation to four-dimensional life in which we understand that there are multiple levels of interpretation such as the composer’s, the producers’, the performers’ and the distant listener’s—computing seems to distill the many-layered four-dimensional space of the text in perfor- mance (i.e., embodied within the performance network of interpretations with the listener in time and space) into a two-dimensional script called “code.” In other words, historically, the musical score is understood as an attempt to represent complex relationships such as the co-occurrence of multiple elements across time and space, a representation that is a provocation to further interpretation.'   
[Page 9](sk://clement2013distant#9)

she cites drucker's notion of [observer-codepence](#todo:)   
[Page 9](sk://clement2013distant#9)

### Audacity ###

'Likewise, instead of reading a two-dimensional visualisation as the inevitable result (or complete representation) of data analysis, we learn to read visualisations as musical scores, as signposts pointing towards many possible interpretive “results” or readings' <- the next step clearly to make them *actual* scores...?   
[Page 10](sk://clement2013distant#10)

'That is, the reader reads the musical score with the necessary perspective of capta rather than data because she expects the musical graphical representation to be, not only based on interpretation but also open to interpretation and meant to be played, to be spatialised in time and embodied by voices. Likewise, mindful of the situated hermeneutical framework that we bring to our readings of all data visualisations, we can learn to create and read computational visualisations as capta.'  <- and so, if we move beyond visualization and attend to the other senses, the emphasis on 'data' naturally would shift to 'capta' more fully?   
[Page 10](sk://clement2013distant#10)

-> discussing using audacity's native visualization tools to understand sound-as-visualization - "Unlike a waveform, a spectrogram shows the information necessary to plot prosody features that include timbre and accent, features to which Bernstein and others have attributed meaning-making properties."   
[Page 13](sk://clement2013distant#13)

### ProseVis ###

http://tclement.ischool.utexas.edu/ProseVis. <- tool to visualize the 'pre-speech potential of sound'    
[Page 14](sk://clement2013distant#14)

it visualises the XML transcription that OpenMary produces in the process of creating an audio file. <- makes me think of Rob's raspberry pi device for sonifying the data lost in OCR...   
[Page 15](sk://clement2013distant#15)

'the ProseVis interface encourages interpretive activity in which the reader engages in a performance of all of these elements, enacted within the same kind of multilayered context of “observer-codependence” that an entourage of composers, producers, performers, and audience members would bring to a real time performance.'   
[Page 17](sk://clement2013distant#17)

### What reading Stein's texts with digital tools can tell us about digital humanities scholarship ###

'The traditions reflected in a computational visualisation are always part of a hermeneutic framework that is also always part of a history of technological and methodological remediations.' <- see also tara copplestone on photobashing & remediation in archaeology   
[Page 18](sk://clement2013distant#18)

### Conclusion ###

'As a culture, we use sound to make meaning, but we have sublimated its study because, like studying “noise,” studying sound is inconvenient, logistically burdensome in terms of the richness of the resulting patterns, and requires a daunting degree of agency from the interpreter, who must establish new methodologies for interpretation.' <- yeppers.   
[Page 24](sk://clement2013distant#24)
